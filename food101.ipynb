{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d4c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0037ab8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237989bafef847728de2229059cc3a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636cc602907d4909bd5fccaba0704ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00008.parquet:   0%|          | 0.00/490M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa0fd5e780a420a99b724ee41014b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00008.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3cedec3b14ed9ba6867f3ac476e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00008.parquet:   0%|          | 0.00/472M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545531354da54e25b8b7898c116e26e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00008.parquet:   0%|          | 0.00/464M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39561af3b854537a9b8969b611993ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00008.parquet:   0%|          | 0.00/475M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d161570f30d34dd78e1425819c30be3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00008.parquet:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f56dec0d71540dd9c0c7c505031a0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00008.parquet:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9324790baec44c769b6b5444c7bde4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00008.parquet:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c404550119064422894ee38995523da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00003.parquet:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b489fb55e6d94945bb8c53e5f7de6b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00001-of-00003.parquet:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3897aec9c2042c7adc78eb011eed52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00002-of-00003.parquet:   0%|          | 0.00/426M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01559fc893549d0a7f0ab9bc0448a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/75750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3fc53cbb134f16826f1e13e825f93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/25250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('ethz/food101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6af2e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 75750\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 25250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056a2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae63b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def save_example(index, mode, global_path, all_data):\n",
    "    try:\n",
    "        item = all_data[index]\n",
    "        image, label = item['image'], item['label']\n",
    "        image = image.convert(\"RGB\")\n",
    "        filename = f'{index}_{mode}.png'\n",
    "        image_path = global_path / filename\n",
    "        image.save(image_path, format='png')\n",
    "        return image_path, label, filename\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] image with index {index} is missed: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_data(target_dir='food101', mode='train', num_workers=8):\n",
    "    all_data = datasets.load_dataset('ethz/food101')[mode]\n",
    "\n",
    "    global_path = Path(target_dir) / 'data'\n",
    "    global_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fpath, targets, names = [], [], []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        from functools import partial\n",
    "        save_func = partial(save_example, mode=mode, global_path=global_path, all_data=all_data)\n",
    "        futures = [executor.submit(save_func, i) for i in range(len(all_data))]\n",
    "\n",
    "        for future in tqdm(futures, desc=\"Сохранение изображений\"):\n",
    "            res = future.result()\n",
    "            if res is None:\n",
    "                continue\n",
    "            path, label, name = res\n",
    "            fpath.append(path)\n",
    "            targets.append(label)\n",
    "            names.append(name)\n",
    "\n",
    "    df = pd.DataFrame({'fpath': fpath, 'target': targets, 'name': names})\n",
    "    df = df.sort_values(by='target')\n",
    "\n",
    "    map_file_path = Path(target_dir) / f\"{mode}_map.csv\"\n",
    "    df.to_csv(map_file_path, index=False)\n",
    "    print(f\"Downloading is done!\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7601591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение изображений:  82%|████████▏ | 62340/75750 [04:15<00:51, 260.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ошибка] Пропущен элемент 62336: 'utf-8' codec can't decode byte 0x83 in position 34: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Сохранение изображений: 100%|██████████| 75750/75750 [05:08<00:00, 245.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено 75749 изображений в check_dir/train_map.csv\n"
     ]
    }
   ],
   "source": [
    "get_data('check_dir', num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598cf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/valetov/EF25_NIPS/check_dir/train_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_split(df, num_samples, random_state):\n",
    "        split_samples = []\n",
    "        split_ids = []\n",
    "        for class_id in range(101):\n",
    "            class_samples = df[df[\"target\"] == class_id].sample(\n",
    "                num_samples, random_state=random_state\n",
    "            )\n",
    "            split_samples.append(class_samples)\n",
    "            split_ids.extend(class_samples.index)\n",
    "        return split_samples, split_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c03538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_uniform_split(df, target_dir='food101', amount_of_clients=10):\n",
    "    target_sizes = np.unique(df['target'], return_counts=True)[1]\n",
    "    clients = []\n",
    "    \n",
    "    for size in target_sizes:\n",
    "        for_each_client = size // amount_of_clients\n",
    "        diff =  size % amount_of_clients\n",
    "        \n",
    "        client_dist = [[i+1] * for_each_client for i in range(10)]\n",
    "        clients.append(np.concatenate(client_dist))\n",
    "        if diff != 0:\n",
    "            clients.append([amount_of_clients+1]*diff) if diff !=0 else 0\n",
    "        \n",
    "    df['clients'] = np.concatenate(clients)\n",
    "    path_to_save = Path(target_dir) / f'{amount_of_clients}_clients_trin_map_file.csv'\n",
    "    \n",
    "    df.to_csv(path_to_save, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48c27e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('target')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52572995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pathology_split(df, std, target_dir='food101', amount_of_clients=10, random_state=42):\n",
    "    mean = len(df) // amount_of_clients\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    amount_for_each_client = [rng.integers(mean - int(mean*std), mean + int(mean*std)) for _ in range(amount_of_clients-1)]\n",
    "    amount_for_each_client.append(len(df) - sum(amount_for_each_client))\n",
    "    \n",
    "    for i in range(100):\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    clients = np.concatenate([[i+1] * amount_for_each_client[i] for i in range(amount_of_clients)])\n",
    "    df['client'] = clients\n",
    "    \n",
    "    path_to_save = Path(target_dir) / f'{amount_of_clients}_clients_pathology_split_train_map_file.csv'\n",
    "    df.to_csv(path_to_save, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bdc8b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexible_split(df, total_clients=10, head_classes=20, head_clients=2, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    num_classes = df['target'].nunique()\n",
    "    clients = [[] for _ in range(total_clients)]\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        class_df = df[df[\"target\"] == class_id]\n",
    "        indices = class_df.sample(frac=1, random_state=random_state).index.tolist()\n",
    "\n",
    "        if len(indices) < total_clients * 2:\n",
    "            raise ValueError(f\"Not enough samples in class {class_id}: minimum {total_clients * 2} is needed\")\n",
    "\n",
    "        for i in range(total_clients):\n",
    "            clients[i].extend(indices[i * 2 : (i + 1) * 2])\n",
    "\n",
    "        remaining = indices[total_clients * 2:]\n",
    "\n",
    "        if class_id < head_classes:\n",
    "            for i, idx in enumerate(remaining):\n",
    "                client_id = i % head_clients\n",
    "                clients[client_id].append(idx)\n",
    "        else:\n",
    "            for i, idx in enumerate(remaining):\n",
    "                client_id = head_clients + (i % (total_clients - head_clients))\n",
    "                clients[client_id].append(idx)\n",
    "\n",
    "    return clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b9d0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_groups_to_df(df, clients):\n",
    "    df = df.copy()\n",
    "    client_column = pd.Series(index=df.index, dtype=int)\n",
    "\n",
    "    for client_id, indices in enumerate(clients):\n",
    "        client_column.loc[indices] = client_id\n",
    "\n",
    "    df['client'] = client_column.astype(np.int64)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06ceed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = flexible_split(df)  # из предыдущего шага\n",
    "df_with_groups = assign_groups_to_df(df, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52be8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_with_groups[df_with_groups['client'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5b70e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/valetov/EF25_NIPS/food101/image_data/food101_hetero_map_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2879f40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 71912/71912 [16:55<00:00, 70.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (R,G,B): [0.54936988 0.44513756 0.34351461]\n",
      "Std  (R,G,B): [0.27317306 0.27592136 0.27996224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ваш DataFrame\n",
    "# df = pd.DataFrame({'path': [...список путей к изображениям...]})\n",
    "\n",
    "# Инициализируем сумматоры\n",
    "# Предполагаем, что все изображения — RGB (3 канала)\n",
    "sum_channels   = np.zeros(3, dtype=np.float64)\n",
    "sum_sq_channels = np.zeros(3, dtype=np.float64)\n",
    "n_pixels_total = 0\n",
    "\n",
    "for img_path in tqdm(df['fpath'], desc=\"Processing images\"):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0  # масштабируем в [0,1]\n",
    "    h, w, c = arr.shape\n",
    "\n",
    "    # Суммы по каналам\n",
    "    sum_channels    += arr.sum(axis=(0,1))\n",
    "    sum_sq_channels += (arr ** 2).sum(axis=(0,1))\n",
    "    n_pixels_total  += h * w\n",
    "\n",
    "# Среднее по каждому каналу\n",
    "mean = sum_channels / n_pixels_total\n",
    "\n",
    "# Дисперсия: E[X^2] − (E[X])^2\n",
    "var  = sum_sq_channels / n_pixels_total - mean**2\n",
    "std  = np.sqrt(var)\n",
    "\n",
    "print(\"Mean (R,G,B):\", mean)\n",
    "print(\"Std  (R,G,B):\", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3660867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
